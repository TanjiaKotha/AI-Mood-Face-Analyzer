<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Mood & Face Analyzer</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }

        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

        .video-container {
            position: relative;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        #video {
            border-radius: 0.75rem;
            transform: scaleX(-1);
            -webkit-transform: scaleX(-1);
        }

        canvas {
            position: absolute;
            top: 0;
            left: 0;
            transform: scaleX(-1);
            -webkit-transform: scaleX(-1);
        }

        .loader {
            border: 5px solid #f3f3f3;
            border-top: 5px solid #3498db;
            border-radius: 50%;
            width: 50px;
            height: 50px;
            animation: spin 1s linear infinite;
        }

        @keyframes spin {
            0% {
                transform: rotate(0deg);
            }
            100% {
                transform: rotate(360deg);
            }
        }
    </style>
</head>

<body class="bg-slate-900 text-white flex flex-col items-center justify-center min-h-screen p-4">

    <div class="w-full max-w-4xl mx-auto">
        <header class="text-center mb-6">
            <h1 class="text-4xl font-bold text-sky-400">AI Mood & Face Analyzer</h1>
            <p class="text-slate-400 mt-2">Point your camera at a face and click "Analyze" to see the magic!</p>
        </header>

        <main class="grid grid-cols-1 md:grid-cols-3 gap-8 items-start">
            <!-- Video and Analysis Button -->
            <div class="md:col-span-2 bg-slate-800 p-4 rounded-xl shadow-lg border border-slate-700">
                <div id="loader-container" class="flex flex-col items-center justify-center h-96">
                    <div class="loader"></div>
                    <p id="loading-message" class="mt-4 text-slate-300">Loading AI Models...</p>
                </div>
                <div class="video-container hidden" id="video-container">
                    <video id="video" width="720" height="560" autoplay muted></video>
                </div>
                 <div class="mt-4 flex justify-center">
                    <button id="analyzeBtn" class="bg-sky-500 hover:bg-sky-600 text-white font-bold py-3 px-6 rounded-lg transition-all duration-300 shadow-md disabled:bg-slate-600 disabled:cursor-not-allowed">
                        Analyze Face
                    </button>
                </div>
            </div>

            <!-- Detection Report Card -->
            <div class="bg-slate-800 p-6 rounded-xl shadow-lg border border-slate-700">
                <h2 class="text-2xl font-semibold mb-4 border-b border-slate-600 pb-2 text-sky-300">Detection Report</h2>
                <div class="space-y-4 text-lg">
                    <div>
                        <span class="font-medium text-slate-400">Age:</span>
                        <span id="age" class="font-bold text-xl ml-2 text-white">--</span>
                    </div>
                    <div>
                        <span class="font-medium text-slate-400">Gender:</span>
                        <span id="gender" class="font-bold text-xl ml-2 text-white">--</span>
                    </div>
                    <div>
                        <span class="font-medium text-slate-400">Expression:</span>
                        <span id="expression" class="font-bold text-xl ml-2 text-white">--</span>
                    </div>
                     <div>
                        <span class="font-medium text-slate-400">Mood Rating:</span>
                        <span id="mood" class="font-bold text-xl ml-2 text-white">-- / 10</span>
                    </div>
                </div>
                 <p id="no-face-message" class="text-amber-400 mt-4 text-center hidden">
                    No face detected. Please try again.
                </p>
            </div>
        </main>
    </div>

    <script>
        const video = document.getElementById('video');
        const analyzeBtn = document.getElementById('analyzeBtn');
        const loaderContainer = document.getElementById('loader-container');
        const videoContainer = document.getElementById('video-container');
        const loadingMessage = document.getElementById('loading-message');
        const noFaceMessage = document.getElementById('no-face-message');
        
        // Disable button initially
        analyzeBtn.disabled = true;

        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights'),
            faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights'),
            faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights'),
            faceapi.nets.faceExpressionNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights'),
            faceapi.nets.ageGenderNet.loadFromUri('https://cdn.jsdelivr.net/gh/justadudewhohacks/face-api.js@0.22.2/weights'),
        ]).then(startVideo).catch(err => {
            loadingMessage.innerText = "Failed to load AI models. Please refresh the page.";
            console.error(err);
        });

        function startVideo() {
            navigator.mediaDevices.getUserMedia({ video: {} })
                .then(stream => {
                    video.srcObject = stream;
                })
                .catch(err => {
                    console.error('Error accessing webcam:', err);
                    loadingMessage.innerText = "Could not access the webcam. Please grant permission and refresh.";
                });
        }
        
        video.addEventListener('loadedmetadata', () => {
            loaderContainer.classList.add('hidden');
            videoContainer.classList.remove('hidden');
            loadingMessage.innerText = "Ready to Analyze!";
            analyzeBtn.disabled = false;
        });

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video);
            // We append the canvas to the container, but it will be drawn on during analysis
            document.querySelector('.video-container').append(canvas); 
            const displaySize = { width: video.width, height: video.height };
            faceapi.matchDimensions(canvas, displaySize);

            // Add the event listener for the button
            analyzeBtn.addEventListener('click', async () => {
                // Clear previous results and messages
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);
                noFaceMessage.classList.add('hidden');
                resetReport();

                // Show loading state on button
                analyzeBtn.disabled = true;
                analyzeBtn.innerText = 'Analyzing...';
                
                const detections = await faceapi.detectSingleFace(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions().withAgeAndGender();
                
                if (detections) {
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);
                    faceapi.draw.drawDetections(canvas, resizedDetections);
                    // faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
                    // faceapi.draw.drawFaceExpressions(canvas, resizedDetections);

                    updateReport(detections);
                } else {
                    noFaceMessage.classList.remove('hidden');
                }

                // Restore button state
                analyzeBtn.disabled = false;
                analyzeBtn.innerText = 'Analyze Face';
            });
        });

        function updateReport(detections) {
            const ageEl = document.getElementById('age');
            const genderEl = document.getElementById('gender');
            const expressionEl = document.getElementById('expression');
            const moodEl = document.getElementById('mood');

            // Age & Gender
            ageEl.innerText = Math.round(detections.age);
            genderEl.innerText = detections.gender;

            // Expressions
            if (detections.expressions) {
                let primaryExpression = 'neutral';
                let maxConfidence = 0;
                for (const [expression, confidence] of Object.entries(detections.expressions)) {
                    if (confidence > maxConfidence) {
                        maxConfidence = confidence;
                        primaryExpression = expression;
                    }
                }
                expressionEl.innerText = `${primaryExpression} (${(maxConfidence * 100).toFixed(1)}%)`;
                moodEl.innerText = `${getMoodRating(primaryExpression)} / 10`;
            }
        }
        
        function resetReport() {
            document.getElementById('age').innerText = '--';
            document.getElementById('gender').innerText = '--';
            document.getElementById('expression').innerText = '--';
            document.getElementById('mood').innerText = '-- / 10';
        }

        function getMoodRating(expression) {
            switch (expression) {
                case 'happy': return 10;
                case 'surprised': return 8;
                case 'neutral': return 6;
                case 'disgusted': return 3;
                case 'sad': return 2;
                case 'fearful': return 2;
                case 'angry': return 1;
                default: return 5;
            }
        }
    </script>
</body>
</html>


